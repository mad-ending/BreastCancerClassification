{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from evaluation import *\n",
    "from feature_scaler import *\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMs can handle non-linear data by mapping it into a higher-dimensional space through the kernel trick. This transformation enables SVMs to find hyperplanes in the new space, effectively handling complex decision boundaries.\n",
    "\n",
    "Here are common types of kernels used in Support Vector Machines (SVMs), each explained in one line:\n",
    "\n",
    "1. **Linear Kernel**: It creates a linear decision boundary and works well for linearly separable data.\n",
    "2. **Polynomial Kernel**: It allows for non-linear decision boundaries and is useful when data has polynomial relationships.\n",
    "3. **Radial Basis Function (RBF) Kernel**: It is versatile and suitable for various data types, offering non-linear decision boundaries based on the similarity to data points.\n",
    "4. **Sigmoid Kernel**: It can model sigmoidal decision boundaries and is often used in binary classification problems.\n",
    "5. **Custom Kernels**: Kernels can be customized to match the specific characteristics of your data, providing flexibility for unique scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/breast-cancer.csv')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['diagnosis'] = encoder.fit_transform(df['diagnosis'])\n",
    "df = df.drop(columns=[\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split and scaling\n",
    "X = df.drop(columns=[\"diagnosis\"])\n",
    "y = df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_ss, X_test_ss = standard_scaler(X_train, X_test) # Standard Scaler\n",
    "X_train_mms, X_test_mms = min_max_scaler(X_train, X_test) # Min-Max Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing features when the correlation between them exceeds a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr = X.corr(numeric_only=True).round(3)\n",
    "correlation_threshold = 0.9\n",
    "upper_matrix = X_corr.where(np.triu(np.ones(X_corr.shape), k=1).astype(bool))\n",
    "features_to_drop = [x for x in upper_matrix.columns if any(upper_matrix[x] > correlation_threshold)]\n",
    "X_corr = X.drop(X[features_to_drop], axis=1)\n",
    "\n",
    "X_corr_train, X_corr_test = train_test_split(X_corr, test_size=0.2, random_state=42)\n",
    "X_corr_train_ss, X_corr_test_ss = standard_scaler(X_corr_train, X_corr_test) # Standard Scaler\n",
    "X_corr_train_mms, X_corr_test_mms = min_max_scaler(X_corr_train, X_corr_test) # Min-Max Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "\n",
    "# With Feature Scaling\n",
    "xgb_classifier_scaled = XGBClassifier()\n",
    "xgb_classifier_scaled.fit(X_train_ss, y_train)\n",
    "y_pred = xgb_classifier_scaled.predict(X_test_ss)\n",
    "score.append(evaluate(y_test, y_pred))\n",
    "\n",
    "xgb_classifier_scaled = XGBClassifier()\n",
    "xgb_classifier_scaled.fit(X_corr_train_ss, y_train)\n",
    "y_pred = xgb_classifier_scaled.predict(X_corr_test_ss)\n",
    "score.append(evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pca = [0,0,0,0,0,0]\n",
    "tmp_pca2 = [0,0,0,0,0,0]\n",
    "\n",
    "import warnings\n",
    "for n in range(2, 20):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_train_ss)\n",
    "    X_test_pca = pca.transform(X_test_ss)\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = evaluate(y_test, y_pred, False)\n",
    "    if tmp_pca[0] < tmp[0]:\n",
    "        tmp_pca = tmp\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_corr_train_ss)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_corr_train_ss)\n",
    "    X_test_pca = pca.transform(X_corr_test_ss)\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = evaluate(y_test, y_pred, False)\n",
    "    if tmp_pca2[0] < tmp[0]:\n",
    "        tmp_pca2 = tmp\n",
    "\n",
    "score.append(tmp_pca)\n",
    "score.append(tmp_pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard Scaler</th>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.956036</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.956088</td>\n",
       "      <td>0.951032</td>\n",
       "      <td>[[69, 2], [3, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Scaler Corr</th>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973742</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>0.974288</td>\n",
       "      <td>[[69, 2], [1, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Standard Scaler</th>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.982369</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.982937</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>[[71, 0], [2, 41]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Standard Scaler Corr</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.938457</td>\n",
       "      <td>0.932362</td>\n",
       "      <td>[[68, 3], [4, 39]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy        F1    Recall  Precision       AUC   \n",
       "Standard Scaler           0.956140  0.956036  0.956140   0.956088  0.951032  \\\n",
       "Standard Scaler Corr      0.973684  0.973742  0.973684   0.973958  0.974288   \n",
       "PCA Standard Scaler       0.982456  0.982369  0.982456   0.982937  0.976744   \n",
       "PCA Standard Scaler Corr  0.938596  0.938450  0.938596   0.938457  0.932362   \n",
       "\n",
       "                            Confusion Matrix  \n",
       "Standard Scaler           [[69, 2], [3, 40]]  \n",
       "Standard Scaler Corr      [[69, 2], [1, 42]]  \n",
       "PCA Standard Scaler       [[71, 0], [2, 41]]  \n",
       "PCA Standard Scaler Corr  [[68, 3], [4, 39]]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score,\n",
    "    index=['Standard Scaler', 'Standard Scaler Corr','PCA Standard Scaler', 'PCA Standard Scaler Corr'], \n",
    "    columns=['Accuracy', 'F1', 'Recall', 'Precision', 'AUC', 'Confusion Matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [] \n",
    "model = SVC()\n",
    "model.fit(X_train_mms, y_train)\n",
    "y_pred = model.predict(X_test_mms)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_corr_train_mms, y_train)\n",
    "y_pred = model.predict(X_corr_test_mms)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train_ss, y_train)\n",
    "y_pred = model.predict(X_test_ss)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_corr_train_ss, y_train)\n",
    "y_pred = model.predict(X_corr_test_ss)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pca = [0,0,0,0,0,0]\n",
    "tmp_pca2 = [0,0,0,0,0,0]\n",
    "\n",
    "import warnings\n",
    "for n in range(2, 20):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_train_mms)\n",
    "    X_test_pca = pca.transform(X_test_mms)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = evaluate(y_test, y_pred, False)\n",
    "    if tmp_pca[0] < tmp[0]:\n",
    "        tmp_pca = tmp\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_corr_train_ss)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_corr_train_mms)\n",
    "    X_test_pca = pca.transform(X_corr_test_mms)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = evaluate(y_test, y_pred, False)\n",
    "    if tmp_pca2[0] < tmp[0]:\n",
    "        tmp_pca2 = tmp\n",
    "\n",
    "score.append(tmp_pca)\n",
    "score.append(tmp_pca2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pca = [0,0,0,0,0,0]\n",
    "tmp_pca2 = [0,0,0,0,0,0]\n",
    "\n",
    "import warnings\n",
    "for n in range(2, 20):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_train_ss)\n",
    "    X_test_pca = pca.transform(X_test_ss)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = evaluate(y_test, y_pred, False)\n",
    "    if tmp_pca[0] < tmp[0]:\n",
    "        tmp_pca = tmp\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_corr_train_ss)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_corr_train_ss)\n",
    "    X_test_pca = pca.transform(X_corr_test_ss)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = evaluate(y_test, y_pred, False)\n",
    "    if tmp_pca2[0] < tmp[0]:\n",
    "        tmp_pca2 = tmp\n",
    "\n",
    "score.append(tmp_pca)\n",
    "score.append(tmp_pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Min-Max Scaler</th>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973621</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973719</td>\n",
       "      <td>0.969702</td>\n",
       "      <td>[[70, 1], [2, 41]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min-Max Scaler Corr</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.938457</td>\n",
       "      <td>0.932362</td>\n",
       "      <td>[[68, 3], [4, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Scaler</th>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.982369</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.982937</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>[[71, 0], [2, 41]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Scaler Corr</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.943990</td>\n",
       "      <td>[[68, 3], [3, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Min-Max Scaler</th>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.478046</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[[71, 0], [43, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Min-MAx Scaler Corr</th>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973621</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973719</td>\n",
       "      <td>0.969702</td>\n",
       "      <td>[[70, 1], [2, 41]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Standard Scaler</th>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.478046</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[[71, 0], [43, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Standard Scaler Corr</th>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.956237</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.956488</td>\n",
       "      <td>0.955617</td>\n",
       "      <td>[[68, 3], [2, 41]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy        F1    Recall  Precision       AUC   \n",
       "Min-Max Scaler            0.973684  0.973621  0.973684   0.973719  0.969702  \\\n",
       "Min-Max Scaler Corr       0.938596  0.938450  0.938596   0.938457  0.932362   \n",
       "Standard Scaler           0.982456  0.982369  0.982456   0.982937  0.976744   \n",
       "Standard Scaler Corr      0.947368  0.947368  0.947368   0.947368  0.943990   \n",
       "PCA Min-Max Scaler        0.622807  0.478046  0.622807   0.387889  0.500000   \n",
       "PCA Min-MAx Scaler Corr   0.973684  0.973621  0.973684   0.973719  0.969702   \n",
       "PCA Standard Scaler       0.622807  0.478046  0.622807   0.387889  0.500000   \n",
       "PCA Standard Scaler Corr  0.956140  0.956237  0.956140   0.956488  0.955617   \n",
       "\n",
       "                            Confusion Matrix  \n",
       "Min-Max Scaler            [[70, 1], [2, 41]]  \n",
       "Min-Max Scaler Corr       [[68, 3], [4, 39]]  \n",
       "Standard Scaler           [[71, 0], [2, 41]]  \n",
       "Standard Scaler Corr      [[68, 3], [3, 40]]  \n",
       "PCA Min-Max Scaler        [[71, 0], [43, 0]]  \n",
       "PCA Min-MAx Scaler Corr   [[70, 1], [2, 41]]  \n",
       "PCA Standard Scaler       [[71, 0], [43, 0]]  \n",
       "PCA Standard Scaler Corr  [[68, 3], [2, 41]]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score,\n",
    "    index=['Min-Max Scaler', 'Min-Max Scaler Corr', 'Standard Scaler', 'Standard Scaler Corr', 'PCA Min-Max Scaler', 'PCA Min-MAx Scaler Corr', 'PCA Standard Scaler', 'PCA Standard Scaler Corr'], \n",
    "    columns=['Accuracy', 'F1', 'Recall', 'Precision', 'AUC', 'Confusion Matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
