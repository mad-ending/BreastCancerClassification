{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Classifier based on applying Bayes' theorem with strong, naive independence assumptions between the features.\n",
    "\n",
    "Naive Bayes Classifier formula can be written based on Bayes theorem as:\n",
    "$$P(y|X) = \\frac{P(X|y) \\cdot P(y)}{P(X)}$$\n",
    "$y$ - class labels we want to predict,\n",
    "$X$ - feature vector.\n",
    "\n",
    "We assume that features are mutually independent (reason for it's naivety):\n",
    "$$P(y|X) = \\frac{P(x_1|y) \\cdot P(x_2|y) \\cdot ... \\cdot P(x_n|y) \\cdot P(y)}{P(X)}$$\n",
    "\n",
    "We select:\n",
    "$$y = argmax_y P(y|X) = argmax_y \\frac{P(x_1|y) \\cdot P(x_2|y) \\cdot ... \\cdot P(x_n|y) \\cdot P(y)}{P(X)}$$\n",
    "$$y = argmax_y P(x_1|y) \\cdot P(x_2|y) \\cdot ... \\cdot P(x_n|y) \\cdot P(y)$$\n",
    "Because result can we very small, we do a little trick below:\n",
    "$$y = argmax_y log(P(x_1|y)) + log(P(x_2|y)) + ... + log(P(x_n|y)) + log(P(y))$$\n",
    "$P(y)$ - prior probability, how often certain class label occurs\n",
    "\n",
    "$P(x_i|y)$ - class conditional probability, calucated with Gaussian distribution:\n",
    "$$ P(x_i|y) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_y}} \\cdot e^{-\\frac{1}{2}(\\frac{x_i - \\mu_y}{\\sigma_y})^2}$$\n",
    "$\\mu_y$ - mean, $\\sqrt{2\\pi \\sigma^2_y}$ - standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from evaluation import *\n",
    "from feature_scaler import *\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/breast-cancer.csv')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['diagnosis'] = encoder.fit_transform(df['diagnosis'])\n",
    "df = df.drop(columns=[\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split and scaling\n",
    "X = df.drop(columns=[\"diagnosis\"])\n",
    "y = df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_ss, X_test_ss = standard_scaler(X_train, X_test) # Standard Scaler\n",
    "X_train_mms, X_test_mms = min_max_scaler(X_train, X_test) # Min-Max Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing features when the correlation between them exceeds a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr = X.corr(numeric_only=True).round(3)\n",
    "correlation_threshold = 0.9\n",
    "upper_matrix = X_corr.where(np.triu(np.ones(X_corr.shape), k=1).astype(bool))\n",
    "features_to_drop = [x for x in upper_matrix.columns if any(upper_matrix[x] > correlation_threshold)]\n",
    "X_corr = X.drop(X[features_to_drop], axis=1)\n",
    "\n",
    "X_corr_train, X_corr_test = train_test_split(X_corr, test_size=0.2, random_state=42)\n",
    "X_corr_train_ss, X_corr_test_ss = standard_scaler(X_corr_train, X_corr_test) # Standard Scaler\n",
    "X_corr_train_mms, X_corr_test_mms = min_max_scaler(X_corr_train, X_corr_test) # Min-Max Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Training:\n",
    "    - calculate mean,\n",
    "    - calculate variance,\n",
    "    - frequency of each class.\n",
    "- Predictions:\n",
    "    - calculate y (using Gaussian formula),\n",
    "    - choosing class with highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifierScratch:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.priors = [] # P(x|c)\n",
    "        self.mean = []\n",
    "        self.var = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        for c in self.classes:\n",
    "            sample_of_class = X[y == c]\n",
    "            self.mean.append(sample_of_class.mean(axis=0))\n",
    "            self.var.append(sample_of_class.var(axis=0))\n",
    "            self.priors.append(sample_of_class.shape[0] / float(X.shape[0]))\n",
    "\n",
    "    def pdf(self, x, c): # p(x|c)\n",
    "        n = np.exp(-0.5 * ((x - self.mean[c])/self.var[c])**2)\n",
    "        d = np.sqrt(2 * np.pi * self.var[c])\n",
    "        return n/d\n",
    "\n",
    "    def predict_sample(self, sample):\n",
    "        pred_priors = []\n",
    "        # Probabilities for each class\n",
    "        for i in range(len(self.classes)):\n",
    "            p_c = np.log(self.priors[i])\n",
    "            pred_priors.append(np.sum(np.log(self.pdf(sample, i))) + p_c)\n",
    "\n",
    "        # Class with highest probability\n",
    "        return self.classes[np.argmax(pred_priors)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.predict_sample(x) for x in X]\n",
    "    \n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [] \n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_corr_train, y_train)\n",
    "y_pred = model.predict(X_corr_test)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train_mms, y_train)\n",
    "y_pred = model.predict(X_test_mms)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_corr_train_mms, y_train)\n",
    "y_pred = model.predict(X_corr_test_mms)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train_ss, y_train)\n",
    "y_pred = model.predict(X_test_ss)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_corr_train_ss, y_train)\n",
    "y_pred = model.predict(X_corr_test_ss)\n",
    "score.append(np.array(evaluate(y_test, y_pred, False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pca = [0,0,0,0,0,0]\n",
    "tmp_pca2 = [0,0,0,0,0,0]\n",
    "\n",
    "import warnings\n",
    "for n in range(2, 20):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_train_mms)\n",
    "    X_test_pca = pca.transform(X_test_mms)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = np.array(evaluate(y_test, y_pred, False))\n",
    "    if tmp_pca[0] < tmp[0]:\n",
    "        tmp_pca = tmp\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_corr_train_ss)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_corr_train_mms)\n",
    "    X_test_pca = pca.transform(X_corr_test_mms)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = np.array(evaluate(y_test, y_pred, False))\n",
    "    if tmp_pca2[0] < tmp[0]:\n",
    "        tmp_pca2 = tmp\n",
    "\n",
    "score.append(tmp_pca)\n",
    "score.append(tmp_pca2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pca = [0,0,0,0,0,0]\n",
    "tmp_pca2 = [0,0,0,0,0,0]\n",
    "\n",
    "import warnings\n",
    "for n in range(2, 20):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_train_ss)\n",
    "    X_test_pca = pca.transform(X_test_ss)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = np.array(evaluate(y_test, y_pred, False))\n",
    "    if tmp_pca[0] < tmp[0]:\n",
    "        tmp_pca = tmp\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_corr_train_ss)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train_pca = pca.transform(X_corr_train_ss)\n",
    "    X_test_pca = pca.transform(X_corr_test_ss)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    tmp = np.array(evaluate(y_test, y_pred, False))\n",
    "    if tmp_pca2[0] < tmp[0]:\n",
    "        tmp_pca2 = tmp\n",
    "\n",
    "score.append(tmp_pca)\n",
    "score.append(tmp_pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Without Scaler</th>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.973481</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.974751</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>[[71, 0], [3, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Without Scaler Corr</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920443</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921213</td>\n",
       "      <td>0.909106</td>\n",
       "      <td>[[68, 3], [6, 37]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min-Max Scaler</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.964738</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.958074</td>\n",
       "      <td>[[70, 1], [3, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min-Max Scaler Corr</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920443</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921213</td>\n",
       "      <td>0.909106</td>\n",
       "      <td>[[68, 3], [6, 37]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Scaler</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.964738</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.958074</td>\n",
       "      <td>[[70, 1], [3, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Scaler Corr</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920443</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921213</td>\n",
       "      <td>0.909106</td>\n",
       "      <td>[[68, 3], [6, 37]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Min-Max Scaler</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.964537</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.966784</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>[[71, 0], [4, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Min-Max Scaler Corr</th>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.901500</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.907182</td>\n",
       "      <td>0.881264</td>\n",
       "      <td>[[69, 2], [9, 34]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Standard Scaler</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.964537</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.966784</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>[[71, 0], [4, 39]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Standard Scaler Corr</th>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.883591</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.888720</td>\n",
       "      <td>0.862594</td>\n",
       "      <td>[[68, 3], [10, 33]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy        F1    Recall  Precision       AUC   \n",
       "Without Scaler            0.973684  0.973481  0.973684   0.974751  0.965116  \\\n",
       "Without Scaler Corr       0.921053  0.920443  0.921053   0.921213  0.909106   \n",
       "Min-Max Scaler            0.964912  0.964738  0.964912   0.965205  0.958074   \n",
       "Min-Max Scaler Corr       0.921053  0.920443  0.921053   0.921213  0.909106   \n",
       "Standard Scaler           0.964912  0.964738  0.964912   0.965205  0.958074   \n",
       "Standard Scaler Corr      0.921053  0.920443  0.921053   0.921213  0.909106   \n",
       "PCA Min-Max Scaler        0.964912  0.964537  0.964912   0.966784  0.953488   \n",
       "PCA Min-Max Scaler Corr   0.903509  0.901500  0.903509   0.907182  0.881264   \n",
       "PCA Standard Scaler       0.964912  0.964537  0.964912   0.966784  0.953488   \n",
       "PCA Standard Scaler Corr  0.885965  0.883591  0.885965   0.888720  0.862594   \n",
       "\n",
       "                             Confusion Matrix  \n",
       "Without Scaler             [[71, 0], [3, 40]]  \n",
       "Without Scaler Corr        [[68, 3], [6, 37]]  \n",
       "Min-Max Scaler             [[70, 1], [3, 40]]  \n",
       "Min-Max Scaler Corr        [[68, 3], [6, 37]]  \n",
       "Standard Scaler            [[70, 1], [3, 40]]  \n",
       "Standard Scaler Corr       [[68, 3], [6, 37]]  \n",
       "PCA Min-Max Scaler         [[71, 0], [4, 39]]  \n",
       "PCA Min-Max Scaler Corr    [[69, 2], [9, 34]]  \n",
       "PCA Standard Scaler        [[71, 0], [4, 39]]  \n",
       "PCA Standard Scaler Corr  [[68, 3], [10, 33]]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score,\n",
    "    index=['Without Scaler', 'Without Scaler Corr','Min-Max Scaler', 'Min-Max Scaler Corr', 'Standard Scaler', 'Standard Scaler Corr', 'PCA Min-Max Scaler', 'PCA Min-Max Scaler Corr', 'PCA Standard Scaler', 'PCA Standard Scaler Corr'], \n",
    "    columns=['Accuracy', 'F1', 'Recall', 'Precision', 'AUC', 'Confusion Matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
